---
params:
  hashtag : '' # the hashtag string we searched for
  explHashTag: '' # <- explanatory link for the hashtag
  pubUrl: '' # <- where the results are published
title: 'Twitter hashtag analysis: `r params$hashtag`'
author: "Ben Anderson (`@dataknut`)"
date: 'Last run at: `r Sys.time()`'
output:
  bookdown::html_document2:
    keep_md: yes
    number_sections: yes
    self_contained: no
    toc: yes
    toc_float: yes
    toc_depth: 3
  bookdown::pdf_document2:
    number_sections: yes
    toc: yes
    toc_depth: 3
bibliography: '`r path.expand("~/bibliography.bib")`'
---
```{r knitrSetUp, include=FALSE}
knitr::opts_chunk$set(echo = FALSE) # do not echo code
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(fig_caption = TRUE)
knitr::opts_chunk$set(fig_height = 6) # default, make it bigger to stretch vertical axis
knitr::opts_chunk$set(fig_width = 8) # full width
knitr::opts_chunk$set(tidy = TRUE) # tidy up code in case echo = TRUE
```

```{r codeSetup, include=FALSE}

# Set start time ----
startTime <- proc.time()

# Libraries ----

# additional libs required by this code
reqLibs <- c("data.table",
             "ggplot2",  
             "readr", 
             "reshape2",
             "stringr",
             "knitr", 
             "kableExtra"
             )

print(paste0("Loading the following libraries: ", reqLibs))
# Use Luke's function to require/install/load
hashTagR::loadLibraries(reqLibs)
```

```{r set parameters}
dPath <- "~/Data/twitter/"

```

# Terms of re-use

## License

[CC-BY-SA](https://creativecommons.org/licenses/by-sa/4.0/) unless otherwise noted.

## Citation

 * Anderson, B (`r lubridate::year(today())`) _Twitter hashtag analysis: `r params$hashtag`_. Downloaded from: `r params$pubUrl`.

# Purpose

I've not been in NZ at this time of year before so `r params$hashtag` is a whole new cultural experience.

The idea is to extract and visualise tweets and re-tweets of _`r params$hashtag`_ (see `r params$explHashTag` and the [Forest & Bird voting site](https://www.birdoftheyear.org.nz/)).

Why? Err.... Just. Because.

# How it works

Code borrows extensively from https://github.com/mkearney/rtweet

The analysis used `rtweet` to ask the Twitter search API to extract 'all' tweets containing the _`r params$hashtag`_ hashtags in the '[recent](https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets)' twitterVerse. 

It is therefore possible that not quite all tweets have been extracted although it seems likely that we have captured most recent `human` tweeting which was the main intention. Future work should instead use the Twitter [streaming API](https://dev.twitter.com/streaming/overview).

```{r load Data}
# load from pre-collected ----
message("Load from pre-collected data and check for duplicates")
# https://github.com/dataknut/hashTagR/blob/master/dataProcessing/getBoTY.R
# for testing params$hashtag <- "#birdoftheyear OR #boty"
raw_twDT <- data.table::as.data.table(hashTagR::loadTweets(dPath, params$hashtag)) # we like data.tables

# this data.table will have duplicate entries because:
# 1. we may have run the search mutiple times
# 2. the search results are dynamic - they can change if a tweet is liked, re-tweeted etc as this data is updated

# we don't want duplicates, we just want the most recent tweet record by time of creation and screen_names

rn <- nrow(raw_twDT)
twDT <- unique(raw_twDT, fromLast = TRUE, by = c("created_at", "screen_name") ) # drop duplicates
un <- nrow(twDT)
message("Returning ", hashTagR::tidyNum(un),
        " tweets after dropping ",
        hashTagR::tidyNum(rn - un),
        " duplicates.")
    
twDT <- twDT[, ba_obsDate := lubridate::date(created_at)]
twDT <- twDT[, ba_obsTime := hms::as.hms(created_at)] # this will auto-convert to local time

```

The data has:

 * `r tidyNum(nrow(twDT))` tweets (including `r tidyNum(nrow(twDT[is_quote == "TRUE"]))` quotes and `r tidyNum(nrow(twDT[is_retweet == "TRUE"]))` re-tweets) 
 * from `r tidyNum(uniqueN(twDT$screen_name))` tweeters 
 * between `r min(twDT$created_at)` and `r max(twDT$created_at)` (UTC).

# Analysis

## Tweets and Tweeters over time


```{r setCaptionTimeSeries}
dataCap <- paste0("Source: Data collected from Twitter's REST API via rtweet",
                  "\nAll (re)tweets and quotes containing ", params$hashtag, 
                    " from ",
                      min(twDT$created_at),
                    " to ",
                    max(twDT$created_at)
                    )
```

```{r allDaysChart, fig.height=8, fig.width=9, fig.cap="Number of tweets and tweeters"}

twDT <- twDT[, ba_tweetType := "Tweet"]
twDT <- twDT[is_retweet == TRUE, ba_tweetType := "Re-tweet"]
twDT <- twDT[is_quote == TRUE, ba_tweetType := "Quote"]

plotDT <- twDT[, .(
                 nTweets = .N,
                 nTweeters = uniqueN(screen_name)
               ), keyby = .(ba_obsDate, ba_tweetType)]

  myPlot <- ggplot(plotDT, aes(x = ba_obsDate)) +
    geom_line(aes(y = nTweets, colour = "N tweets")) +
    geom_line(aes(y = nTweeters, colour = "N tweeters")) +
    facet_grid(ba_tweetType ~ .) +
    scale_x_date(date_breaks = "1 day", date_labels = "%a %d %b %Y") +
    theme(strip.text.y = element_text(size = 9, colour = "black", angle = 90)) +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0.5)) +
    theme(legend.position = "bottom") +
    theme(legend.title = element_blank()) +
    labs(caption = dataCap,
         x = "Date",
         y = "Count"
    )

myPlot

```

Figure \@ref(fig:allDaysChart) shows the number of tweets and tweeters in the data extract by day. The quotes, tweets and re-tweets have been separated.

If you are in New Zealand and you are wondering why there are no tweets `today` (`r lubridate::today()`) the answer is that twitter data (and these plots) are working in UTC and (y)our `today()` may not have started yet in UTC. Don't worry, all the tweets are here - it's just our old friend the timezone... :-)

## Who's tweeting?

Next we'll try by screen name.

```{r screenNamesTile, fig.height=8,fig.cap="N tweets per day by screen name"}

plotDT <- twDT[, 
                    .(
                      nTweets = .N
                    ), by = .(screen_name, ba_obsDate)]

tilePlot <- ggplot(plotDT, aes(x = ba_obsDate)) +
    geom_tile(aes(y = screen_name, fill = nTweets)) +
    theme(strip.text.y = element_text(size = 9, colour = "black", angle = 0)) +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0.5)) +
    #scale_x_reverse() + # fix reverse plotting of long
    scale_x_date(date_breaks = "1 day", date_labels = "%a %d %b %Y") +
    scale_fill_gradient(low="green", high = "red") +
    theme(legend.position = "bottom") +
    theme(legend.title = element_blank()) +
    labs(caption = dataCap,
         x = "Date",
         y = "Screen name"
    )
tilePlot
```

Figure \@ref(fig:screenNamesTile) is a really bad visualisation of all tweeters tweeting over time. Each row of pixels is a tweeter (the names are probably illegible) and a green dot indicates a few tweets in the given day while a red dot indicates a lot of tweets.

So let's re-do that for the top 50 tweeters so we can see their tweetStreaks (tm)...

Top tweeters:

```{r topTweeters}
allTweetersDT <- twDT[, .(nTweets = .N), by = screen_name][order(-nTweets)]

kableExtra::kable(caption = "Top 15 tweeters (all days)", 
                  head(allTweetersDT, 15)) %>%
  kable_styling()
```

And their tweetStreaks are shown in Figure \@ref(fig:screenNameTop50)...

```{r screenNameTop50, fig.height=8,fig.cap="N tweets per day minutes by screen name (top 50, reverse alphabetical)"}
myDataCap <- paste0(dataCap,
                    "\nScreen names in reverse alphabetical order"
                          )

matchDT <- head(allTweetersDT,50)
matchDT <- matchDT[, maxT := nTweets]
setkey(matchDT, screen_name)
setkey(twDT, screen_name)

tempDT <- merge(twDT, matchDT)

plotDT <- tempDT[matchDT, 
                    .(
                      nTweets = .N
                    ), keyby = .(maxT,screen_name,ba_obsDate)]

plotDT <- plotDT[order(plotDT$maxT,plotDT$screen_name)]

myPlot <- ggplot(plotDT, aes(x = ba_obsDate)) +
    geom_tile(aes(y = screen_name, fill = nTweets)) +
    theme(strip.text.y = element_text(size = 9, colour = "black", angle = 0)) +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0.5)) +
    scale_x_date(date_breaks = "1 day", date_labels = "%a %d %b %Y") +
    scale_fill_gradient(low="green", high = "red") +
    theme(legend.position = "bottom") +
    theme(legend.title = element_blank()) +
    labs(caption = myDataCap,
         x = "Date",
         y = "Screen name"
    )

myPlot 
```

Any twitterBots...?

## Which birds are mentioned the most (by hashtag)


```{r processHTs}
htDT <- twDT[!is.na(hashtags), .(hashtags, ba_obsDate, ba_tweetType)] # remove any tweets without hashtags. How can there be no hashtags when we searched on hashtags?

# now string split them
# https://stackoverflow.com/questions/33200179/dynamically-assign-number-of-splits-in-data-table-tstrsplit
splits <- max(lengths(strsplit(htDT$hashtags, "|", , fixed=T)))
htDT <- htDT[, paste0("ht", 1:splits) := tstrsplit(hashtags, "|", fixed=T)]
# reshape the list
htLongDT <- reshape2::melt(htDT, id=c("hashtags","ba_obsDate", "ba_tweetType"))
# remove NA
htLongDT <- htLongDT[!is.na(value)]
message("We have ", nrow(htLongDT), " hashtags.")
message("That's about ~ ", round(nrow(htLongDT)/nrow(twDT),2), " hashtags per tweet...")
# process in steps to be clear
htLongDT <- htLongDT[, htOrig := value]
# so that TeamKakī == TeamKaki & takahe == takahē etc https://twitter.com/Thoughtfulnz/status/1046685305569345536

htLongDT <- htLongDT[, htLower := tolower(htOrig)] # lower case

# kakī != kaki
deMacron <- function(original){
  # with thanks to https://twitter.com/Thoughtfulnz/status/1047648312810033152
  macron <- c("ā", "ē", "ī", "ō", "ū") # set macron vowels https://kupu.maori.nz/about/macrons-keyboard-setup
  nonMacron <- c("a", "e", "i", "o", "u") # roman equiv
  return(nonMacron[which(original == macron)])
}

htLongDT <- htLongDT[,htClean := stringr::str_replace_all(htLower,"[āēīōū]",deMacron)]
```

This is very quick and dirty but... Table \@ref(tab:tweetTable) shows the total count of each #hashtag by (re)tweet type. With thanks to [David Hood](https://twitter.com/Thoughtfulnz/status/1046685305569345536) for code to help make sure that kakī == kaki ([etc](https://kupu.maori.nz/about/macrons-keyboard-setup)).


```{r tweetTable}
kableExtra::kable(caption = "Top 20 hashtags in tweets containing #birdoftheyear or #boty",
                  head(htLongDT[, .(count = .N), by = .(hashTag = htClean, type = ba_tweetType)][order(-count)],20)) %>%
  kable_styling()
```

```{r setPlotThreshold}
threshold <- 10
```

Figure \@ref(fig:plotHashtags) plots the daily occurence of these hashtags after removing variants of `#birdOfTheYear` and `#boty` and selecting only those which have more than `r threshold` mentions on any day. For clarity tweets and re-tweets are aggregated. See Section \@ref(problems) for the problems with this #hashTag counting approach.

```{r plotHashtags, fig.height=8, fig.cap="Most mentioned #hashtags per day"}

# remove any which are _only_ birdoftheyear
testDT <- htLongDT[!(grepl("birdoftheyear",htClean,ignore.case = TRUE) | 
                grepl("boty",htClean,ignore.case = TRUE) )]

htTabDT <- testDT[, .(count = .N), keyby = .(ba_obsDate, htClean, ba_tweetType)]

ggplot2::ggplot(htTabDT[count > threshold], aes(x = ba_obsDate, y = htClean, fill = count)) +
  geom_tile() + 
  theme(strip.text.y = element_text(size = 9, colour = "black", angle = 0)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0.5)) +
  scale_x_date(date_breaks = "1 day", date_labels = "%a %d %b %Y") +
  scale_fill_gradient(low="green", high = "red") +
 # facet_grid(ba_tweetType ~ .) +
  theme(legend.position = "bottom") +
  theme(legend.title = element_blank()) +
  labs(caption = paste0(dataCap,"\nReverse alphabetical order"),
       x = "Date",
       y = "Unique hashtags"
  )
  
```

# So who's gonna win? {#cumulative}

No idea. 

There are _a lot_ of problems with this approach (see Section \@ref(problems)) but if the hashtags have any predictive value at all then Figure \@ref(fig:cumulativeHtCounts) should be an indicator of the direction of travel (watch for lines of apparently dis-similar hashtags where the macron fix has failed) and Figure \@ref(fig:htCountsTodate) shows the totals to date.

Figure \@ref(fig:cumulativeHtCounts) uses `plotly` to avoid having to render a large legend - just hover over the lines to see who is who...

```{r cumulativeHtCounts, fig.cap="Cumulative hashtag counts over time"}
plotDT <- htTabDT[, .(count = sum(count)), keyby = .(ba_obsDate,htClean)]
plotDT <- plotDT[, cumCount := cumsum(count), by = htClean]
plotDT <- plotDT[, maxCount := max(cumCount), by = htClean] # so we can filter

linePlot <- ggplot2::ggplot(plotDT[maxCount > 30], aes(x = ba_obsDate, y = cumCount, colour = htClean)) +
  geom_line() + 
  theme(strip.text.y = element_text(size = 9, colour = "black", angle = 0)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0.5)) +
  scale_x_date(date_breaks = "1 day", date_labels = "%a %d %b %Y") +
  theme(legend.position = "none") +
  theme(legend.title = element_blank()) +
  labs(caption = paste0(dataCap,"\nReverse alphabetical order"),
       x = "Date",
       y = "Cumulative count per day"
  )

plotly::ggplotly(linePlot)
```

```{r htCountsTodate, fig.cap="Total hashtag counts to date"}
plotDT <- htTabDT[, .(count = sum(count)), keyby = .(htClean)]

plotDT <- plotDT[, htCleanOr := reorder(htClean, -count)]

ggplot2::ggplot(plotDT[count > 30], aes(x = htCleanOr, y = count, fill = htCleanOr)) +
  geom_col() + 
  theme(strip.text.y = element_text(size = 9, colour = "black", angle = 0)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0.5)) +
  theme(legend.position = "none") +
  theme(legend.title = element_blank()) +
  labs(caption = paste0(dataCap,"\nOnly count > 30 shown"),
       x = "hashtag",
       y = "Count to date"
  )
```

# Problems {#problems}

Loads of them. But primarily:

 * hashTags as indicators: tweets mentioning birds without using a `#<birdName>` hashtag (like [this rather popular one](https://twitter.com/BillBailey/status/1046965452063293447)) will not show up. [#YMMV](https://dictionary.cambridge.org/dictionary/english/ymmv);
 * removing the macrons: the tables and plots display incorrect Māori names. Unfortunately I have not found a way to put them back in the right words (and only the right words).

# About

```{r check runtime}
t <- proc.time() - startTime

elapsed <- t[[3]]
```

Analysis completed in `r elapsed` seconds ( `r round(elapsed/60,2)` minutes) using [knitr](https://cran.r-project.org/package=knitr) in [RStudio](http://www.rstudio.com) with `r R.version.string` running on `r R.version$platform`.

A special mention must go to `https://github.com/mkearney/rtweet` [@rtweet-package] for the twitter API interaction functions.

Other R packages used:

 * base R - for the basics [@baseR]
 * data.table - for fast (big) data handling [@data.table]
 * ggplot2 - for slick graphs [@ggplot2]
 * readr - for nice data loading [@readr]
 * reshape2 - wide to long [@reshape2]
 * rtweet - twitter API search [@rtweet-package]
 * stringr - processing strings [@stringr]
 * knitr, bookdown & kableExtra - to create this document [@knitr,@bookdown, @kableExtra]

# References



